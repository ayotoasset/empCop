---
title: "Convex combination of checkerbords with known margins"
author: "Oskar Laverny"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Convex combination of checkerbords with known margins}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

```

The goal of this vignette is to describe what are convex combinations of copulas and how we implemented them inside the `empCop` package. The actual implemntation only deals with *linear* combinations.

First, if we supose a list of copulas $C_i, i \in {1,...,n}$ all of the same dimension, we should emphasis that $\sum\limits_{i=1}^n \alpha_i C_i$ is still a copula as soon as $\sum\limits_{i=1}^n \alpha_i = 1$ and $\alpha_i >=0 \forall i$. 

This simple *linear* combinaison of copulas can be constructed in R through the following code : 

```{r}
library(copula)
library(empCop)

copulas <- list(
  archmCopula("gumbel",3,dim=2),
  archmCopula("clayton",-1,dim=2)
)

(cop <- ConvexCombCopula(copulas))

plot(rCopula(100,cop))
pCopula(c(0.5,0.7),cop)


```


The number of copulas is not restricte. Avaliables methods are for the moment `rCopula` and `pCopula`. 

For exemple, given a dataset, we could optimise each copula first and them optimise weights, based on some criterion, e.g rmse. 


```{r}
data("LifeCycleSavings")
pseudo_data <- apply(LifeCycleSavings,2,rank)/(nrow(LifeCycleSavings)+1)
d <- ncol(pseudo_data)
pairs(pseudo_data)
```

For exemple, let's start from checkerboards(m=10) with known bivariate clayton margins. Since only the variables 2 to 4 seems to be non-independant, we will calculate cbkmCopulas only for thoose.

```{r}

cbkm_clayton <- function(data,margins,m=5){
  known_copula <- 
    archmCopula("Clayton",dim=2,
                param = coef(fitCopula(
                  archmCopula("Clayton",dim = length(margins)),
                  data[,margins],
                  method="itau")))
  cbkmCopula(data,
             m=m,
             pseudo=TRUE,
             margins_numbers = margins,
             known_cop = known_copula,
             quiet=TRUE
  )
}

couples <- as.matrix(expand.grid(2:4,2:4))
couples <- couples[couples[,1]<couples[,2],]

copulas <- apply(couples,1,function(margins){
  cbkm_clayton(pseudo_data,margins)
})

ccc_equal_weights <- ConvexCombCopula(copulas)

simu <- rCopula(500,ccc_equal_weights)
pairs(rbind(simu,pseudo_data),
      col=c(rep("black",nrow(simu)),rep("red",nrow(pseudo_data))),
      gap=0,
      lower.panel=NULL)

```


This combinasion was taken with equal weights. But we could also try to optimise them. For exmeple, we could compute a predictive performance measure like the RMSE on a leave-one-out context and use it as a criterion.

The "good" model will be the empirical copula. We calculate values of the empirical copula on the dataset when in a leave-ont-out way. Let's choose only 46 points.
```{r}
X <- pseudo_data[sample(1:nrow(pseudo_data),46),]
d = ncol(X)
n = nrow(X)
pEmpCop_loo <- sapply(1:n,function(i_loo){
  sum(colSums(t(X[-i_loo,]) <= X[i_loo,]) == d)
}) / n
```

Now, we also need to compute the different models in a leave-one-out manner : 




```{r}


pcopulas_loo <- sapply(1:n,function(i_loo){
  copulas <- apply(couples,1,function(margins){
  cbkm_clayton(X[-i_loo,],margins)
  })
  sapply(copulas,function(cop){
    pCopula(X[i_loo,],cop)
  })
})


```

Now let's calculate the RMSE per copulas : 

```{r}
rmse_loo <- sapply(1:nrow(pcopulas_loo),function(i){
  sum((pcopulas_loo[i,] - pEmpCop_loo)^2)
})

weights <- (1/rmse_loo)/sum(1/rmse_loo)
```

Using thoose weights, we can calculate a new convex combination of copulas : 

```{r}
ccc_loo <- ConvexCombCopula(copulas,alpha = weights)

simu <- rCopula(500,ccc_loo)
pairs(rbind(simu,X),
      col=c(rep("black",nrow(simu)),rep("red",nrow(X))),
      gap=0,
      lower.panel=NULL)

```


We could compare the kendall's tau matrices : 
```{r}
cor(X,method="kendall")
cor(rCopula(1000,ccc_loo),method="kendall")
```

This implmeentation is not finished because the actual implementation of the pCopula function is clearly not good enough (not fast enough) to go further in the optimisation process. 

The solution to speed things up is to pass coputations to C++ instead of R, Wich we will do soon.








